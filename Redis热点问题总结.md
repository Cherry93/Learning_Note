#### Redis 持久化机制

Redis是一个支持持久化的内存数据库(memcache不支持)，通过持久化机制把内存中的数据同步到硬盘文件来保证数据持久化。每次Redis重启后通过把硬盘文件重新加载到内存，就能达到恢复数据的目的。
实现：单独创建fork一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，内存释放。

持久化主要有以下两种

1. **RDB**

RDB是Redis默认的持久化方式。按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即Snapshot快照存储，对应产生的数据文件为dump.rdb(可以再config文件中自定义名字)，通过config文件中的save参数来定义快照的周期。

    
```redis
# 900秒发生1次改动触发rdb快照
save 900 1
# 300秒发生10次改动触发rdb快照
save 300 10
# 60秒发生1次改动触发rdb快照
save 60 10000
```

2. **AOF**

Redis会将每一个收到的写命令都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容，与rdb不同的是，aof记录的是命令，而rdb是记录的具体数据。


```
# redis 默认不开启aof
appendonly no
# aof文件名自定义
appendfilename "appendonly.aof"
# 一般选择每秒sync一次，这样最多丢失一秒数据
appendfsync everysec
# aof超过多少才触发重写，默认是100%
auto-aof-rewrite-percentage 100
# 当aof超过多大时候重写，默认是64mb，显然64mb太小远不够用，建议设置更大，比如3,5GB等
auto-aof-rewrite-min-size 64mb

```

> 当rdb和aof都开启的时候，系统会优先加载aof

#### 缓存穿透，雪崩

什么是缓存穿透？

> 查询一个一定不存在的值，且此值在数据库中也不存在（比如请求ID为-1的值），所以每次请求必然会命中数据库，从而可能把数据库也弄挂了

解决方案：

1. 布隆过滤器（实现原理详情见同目录另一篇文章'布隆过滤器的Python实现'），将所有可能存在的结果写入过滤器，可能会发生误判（即不存在的数据也判定为存在），但是如果过滤判断的结果为不存在，那么数据是一定不存在于redis中的
2. 如果返回的数据为空，那么仍然将此空结果缓存，并设置一定的过期时间，比如3、5分钟


什么是缓存雪崩？
> 缓存雪崩是指缓存集体失效，即缓存集体过期，请求直接打到数据库，容易弄崩数据库

解决方案：
1. 缓存设置随机的过期时间


#### 过期key删除和内存淘汰策略

过期策略：定期删除+惰性删除

**定期删除**

> redis每100ms会随机抽取一些设置了过期时间的key，检查是否过期，如过期则删除

**惰性删除**

> 在获取某个key的时候，redis会检查一下 ，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会返回任何东西。

如果上述两种过期策略都没能删除掉过期的key，导致大量的过期key堆积在内存中，内存不足时久会走内存淘汰策略


**内存淘汰策略**

redis内存不足时，会采用内存淘汰策略来清楚一些keys，具体策略如下

```
# 在设置了过期时间的key中，用lru算法移除最近使用最少的key
# volatile-lru -> Evict using approximated LRU among the keys with an expire set.
# 移除最近使用最少的key，一般用这个比较好
# allkeys-lru -> Evict any key using approximated LRU.
# 在设置了过期时间的key中，随机移除
# volatile-random -> Remove a random key among the ones with an expire set.
# 全键随机移除
# allkeys-random -> Remove a random key, any key.
# 在设置了过期时间的key中，移除过期时间比较早的key
# volatile-ttl -> Remove the key with the nearest expire time (minor TTL)
# reids配置文件默认，不删除，新写入直接报错
# noeviction -> Don't evict anything, just return an error on write operations.
```

> 如果没有设置key的过期时间,  那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。

#### memcached和redis的区别
1. redis可持久化，memcached不行
2. redis相比较memcached支持更多的数据结构和应用场景比如list，hash，set，zset，事务等
3. redis单个key支持更大的内存容量
4. reids速度更快（单线程，无上下文切换，I/O多路复用）

#### redis常用数据类型
1. string，常用操作有set/get/incr/decr，没啥好说的，有时候用来计数，比如秒杀系统
2. list，可以当作简单的双端队列使用，支持push/pop
3. hash，常用操作hget/hset，用来存储session还是比较方便
4. set，常用作去重用
5. zset，带score的set，可以在算排名的时候用，常用操作zadd/zrange/zrem/zcard

#### 主从相关问题
1. slave通过 slaveof <masterip> <masterport> 命令来指定主机
2. Master 一般不要做任何持久化工作，如RDD和AOF
3. slave开启 AOF 备份数据，策略设置为每秒同步一次(appendfsync everysec)
4. 主从结构不要用树状结构，应该用链表结构，即Master <- Slave1 <- Slave2


#### redis原子性问题
1. redis本身提供的api是具有原子性的，比如set/get，即操作要么成功，要么失败
2. redis事务具有部分原子性，即全体连坐+冤头债主，全体连坐（如果是命令错了比如set打称了gset，那么全体不执行），冤头债主（命令都是都是对的，但是不符合逻辑比如incr一个string值，那么错误的命令不指定，正确的命令依旧执行）


#### redis和mysql一致性问题

redis读的步骤：
1. 如果数据在redis中，那么直接取；
2. 如果数据不在redis中，那么从mysql中取，**然后将数据写入redis** ；
3. 将数据返回给请求

什么是缓存与数据库双写一致问题？
> 仅就查询来说，这里的不一致指的是redis中的数据和mysql中的数据不一致，比如数据库中的库存更新完是900，而redis中的库存由于未更新所以还是1000。从理论上来说，只要设置了过期时间，那么会达到最终一致性，只要缓存过去被删除了，再读数据那么redis和mysql就一致了。

**对于更新操作**

- 先操作数据库，再操作缓存
- 先操作缓存，再操作数据库

无论是先操作数据库还是先操作mysql，都希望这两个操作要么同时成功，要么同时失败，从事务角度看，只要出现一个失败，另外一个也必然失败，如果第一步失败了，那么第二步必然不会执行。

**操作缓存**

- 删除缓存
- 更新缓存

一般采用删除缓存，原因如下：
1. 高并发环境下，无论是先操作数据库还是后操作数据库而言，如果加上更新缓存，那就更加容易导致数据库与缓存数据不一致问题。(删除缓存直接和简单很多)
2. 如果每次更新了数据库，都要更新缓存【这里指的是频繁更新的场景，这会耗费一定的性能】，倒不如直接删除掉。等再次读取时，缓存里没有，那到数据库找，在数据库找到再写到缓存里边(类似懒加载)


**先更新数据库，再删除缓存**

正常情况：

- 先更新数据库，成功
- 再删除缓存，也成功

但是如果原子性被破坏：
- 第一步更新数据库成功，但是第二步删除缓存失败，会导致数据库里是新数据，而缓存里是旧数据，这样就出现了数据不一致。
- 如果第一步就失败了，那么第二步直接不执行。

并发复现情况：

- 缓存刚好失效
- 线程A查询数据库，得一个旧值
- 线程B将新值写入数据库
- 线程B删除缓存
- 线程A将查到的旧值写入缓存

**先删除缓存，再更新数据库**

正常情况：
- 先删除缓存，成功；
- 再更新数据库，也成功；

但是如果原子性被破坏：
- 第一步成功(删除缓存)，第二步失败(更新数据库)，数据库和缓存的数据还是一致的。
- 如果第一步(删除缓存)就失败了，第二步直接不执行，数据库和缓存的数据还是一致的。

并发复现情况：

- 线程A删除了缓存
- 线程B查询，发现缓存已不存在
- 线程B去数据库查询得到旧值
- 线程B将旧值写入缓存
- 线程A将新值写入数据库

可以看出，无论是先更新数据库还是先输出缓存，再高并发情况下都可能出现双写不一致情况，那么有没有解决方案呢？有。

**解决方案**

- 串行化所有操作，所有操作走从队列。
- 先删缓存，再更新数据库，过一会儿再删一次缓存（对于时效敏感的业务操作不适用），用来避免高并发出现的不一致问题。